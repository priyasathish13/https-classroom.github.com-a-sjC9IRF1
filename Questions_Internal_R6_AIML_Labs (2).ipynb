{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions_Internal_R6_AIML_Labs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUZjPnVXGz0Z",
        "colab_type": "text"
      },
      "source": [
        "# The Iris Dataset\n",
        "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
        "\n",
        "The dataset contains a set of 150 records under five attributes - petal length, petal width, sepal length, sepal width and species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOk8Eu4_t70R",
        "colab_type": "text"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCFiuQvvRlnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a112515-c577-4125-835d-78a0bf259428"
      },
      "source": [
        "pip install tensorflow==2.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.27.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.18.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (3.11.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow==2.0) (0.9.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.6.1->tensorflow==2.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.11.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.25.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow-federated 0.11.0 requires enum34~=1.1, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.11.0 has requirement attrs~=18.2, but you'll have attrs 19.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.11.0 has requirement cachetools~=3.1.1, but you'll have cachetools 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.11.0 has requirement grpcio~=1.24.3, but you'll have grpcio 1.27.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6RZUm0p4wYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWi96z-8SyX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-vVQBBqg7DI",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE0EDKvQhEIe",
        "colab_type": "text"
      },
      "source": [
        "### Import dataset\n",
        "- Import iris dataset\n",
        "- Import the dataset using sklearn library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlVZ0Z6DZok9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOOWpD26Haq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "df= load_iris()\n",
        "type(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOuYvCeKdT0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta8YqInTh5v5",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HERt3drbhX0i",
        "colab_type": "text"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- you can get the features using .data method\n",
        "- you can get the features using .target method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cV-_qHAHyvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (df.feature_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3XCJIycduWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (df.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg1A2lkUjFak",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state: 1\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYKNJL85h7pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=df.data\n",
        "y=df.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KVP17Ozaix",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIjqxbhWv1zv",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the labels\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert labels\n",
        "- number of classes: 3\n",
        "- we are doing this to use categorical_crossentropy as loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9vv-_gpyLY9",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBwUJ38bevaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_y=tf.keras.utils.to_categorical(y,num_classes=3,dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovjLyYzWkO9s"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbIFzoPNSyYo",
        "colab_type": "text"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- Define a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FvSbf1UjHtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.layers.advanced_activations import ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOvDeVyShRUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGMy999vlacX"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ibK5Jxm8iL",
        "colab_type": "text"
      },
      "source": [
        "### Add a layer\n",
        "- Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3\n",
        "- Apply Softmax on Dense Layer outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZKrBNSRm_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(30, activation='relu', input_shape=(4,)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhMbQ6wPhlBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4uiTH8plmNX",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJL8n8vcSyYz",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "- Use SGD as Optimizer\n",
        "- Use categorical_crossentropy as loss function\n",
        "- Use accuracy as metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc_-fjIEk1ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy']) #optimizer is the hyper parameter\n",
        "                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfHS2TMtjWTZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sihIGbRll_jT"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ZZCfNGlu0i",
        "colab_type": "text"
      },
      "source": [
        "### Summarize the model\n",
        "- Check model layers\n",
        "- Understand number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elER3F_4ln8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PiP7j3Vmj4p"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWdbfFCXmCHt",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- Give train data as training features and labels\n",
        "- Epochs: 100\n",
        "- Give validation data as testing features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO1c-5tjmBVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "batch_size =150\n",
        "from keras.utils import to_categorical\n",
        "y_binary=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n",
        "history = model.fit(X_train, y_binary, batch_size=batch_size, epochs=epochs, validation_split=.3, verbose=True)\n",
        "loss,accuracy  = model.evaluate(X_test, y_test, verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re9ItAR3yS3J",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liw0IFf9yVqH",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions\n",
        "- Predict labels on one row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5sBybi6mlLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpIMiS-1k4m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.round(model.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aluYxAxxk8Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4s5oAgCk_8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(X_train, y_binary, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSUgMq3m0bG7",
        "colab_type": "text"
      },
      "source": [
        "### Compare the prediction with actual label\n",
        "- Print the same row as done in the previous step but of actual labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5WbwVPyz-qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrTKwbgE7NFT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeoiMbH7djEv",
        "colab_type": "text"
      },
      "source": [
        "# Stock prices dataset\n",
        "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
        "\n",
        "## Description\n",
        "A brief description of columns.\n",
        "- open: The opening market price of the equity symbol on the date\n",
        "- high: The highest market price of the equity symbol on the date\n",
        "- low: The lowest recorded market price of the equity symbol on the date\n",
        "- close: The closing recorded price of the equity symbol on the date\n",
        "- symbol: Symbol of the listed company\n",
        "- volume: Total traded volume of the equity symbol on the date\n",
        "- date: Date of record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSoYY2nII_UW",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9Ws2l6jdLa_"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "407SiobOdLbL",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGqq9f8VdLba",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_88voqAH-O6J",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRHCeJqP-evf",
        "colab_type": "text"
      },
      "source": [
        "### Load the data\n",
        "- load the csv file and read it using pandas\n",
        "- file name is prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4YcffYd1FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell to to mount the google drive if you are using google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B5sfSFarZPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df=pd.read_csv(\"/prices (1).csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDC6cSW_FSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlLKVPVH_BCT",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZxoGynuBeO4t"
      },
      "source": [
        "### Drop null\n",
        "- Drop null values if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yuwJJIeeUaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "376de0f1-fef1-42ad-ac4f-ce84b5d5a74e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 438305 entries, 0 to 438304\n",
            "Data columns (total 7 columns):\n",
            "date      438305 non-null object\n",
            "symbol    438304 non-null object\n",
            "open      438304 non-null float64\n",
            "close     438304 non-null float64\n",
            "low       438304 non-null float64\n",
            "high      438304 non-null float64\n",
            "volume    438304 non-null float64\n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 23.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGOh6QgbtFVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f2525317-2570-45b5-c0cf-e120d1153e8f"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date      0\n",
              "symbol    1\n",
              "open      1\n",
              "close     1\n",
              "low       1\n",
              "high      1\n",
              "volume    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owFxllPbtrxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4BlzVA_gZd",
        "colab_type": "text"
      },
      "source": [
        "### Drop columnns\n",
        "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
        "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKEK8aEE_Csx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=df.drop(['date', 'volume','symbol'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTPhO6v-AiZt",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsZXmF3NAkna",
        "colab_type": "text"
      },
      "source": [
        "### Print the dataframe\n",
        "- print the modified dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKs04iIHAjxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a55aa1f3-3679-4ff7-a3d3-c2c6bf805a48"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high\n",
              "0  123.430000  125.839996  122.309998  126.250000\n",
              "1  125.239998  119.980003  119.940002  125.540001\n",
              "2  116.379997  114.949997  114.930000  119.739998\n",
              "3  115.480003  116.620003  113.500000  117.440002\n",
              "4  117.010002  114.970001  114.089996  117.330002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8u_jlbABTip"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
        "- Take \"open\" \"low\", \"high\" columns as features\n",
        "- Take \"close\" column as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQjCMzUXBJbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df1[['open','low','high']]\n",
        "y=df1[['close']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGtnapgBIJm",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZAKdJ5gcrm",
        "colab_type": "text"
      },
      "source": [
        "### Create train and test sets\n",
        "- Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KalRqA6Rgqsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAKzlxZBz0z",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7BU2qxEg0Ki",
        "colab_type": "text"
      },
      "source": [
        "### Scaling\n",
        "- Scale the data (features only)\n",
        "- Use StandarScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcO8SlhPhBkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the scaler \n",
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "# Scale the train set\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "# Scale the test set\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3TWpN0nVTpUx"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sj0LYNkhR-L",
        "colab_type": "text"
      },
      "source": [
        "### Convert data to NumPy array\n",
        "- Convert features and labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19GcKNRwysz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbESkpe7hiVk",
        "colab_type": "text"
      },
      "source": [
        "### Reshape features\n",
        "- Reshape the features to make it suitable for input in the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H1MId1F1JYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4b1fde9c-a86f-454e-c1c0-b0cbe1d488e5"
      },
      "source": [
        "X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
        "X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
        "y_train.reshape(y_train.shape[0],y_train.shape[1],1)\n",
        "y_test.reshape(y_test.shape[0],y_test.shape[1],1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 42.860001]],\n",
              "\n",
              "       [[103.650002]],\n",
              "\n",
              "       [[ 52.66    ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 36.419998]],\n",
              "\n",
              "       [[ 93.400002]],\n",
              "\n",
              "       [[ 71.370003]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmXUGc2oTspa"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl2M9whFh6mh",
        "colab_type": "text"
      },
      "source": [
        "### Define Model\n",
        "- Initialize a Sequential model\n",
        "- Add a Flatten layer\n",
        "- Add a Dense layer with one neuron as output\n",
        "  - add 'linear' as activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiBpORmiegL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34ef9594-7acf-40f6-98b5-067a826c4bee"
      },
      "source": [
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "\n",
        "# define the model architecture\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add an input layer \n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20,activation=\"sigmoid\"))\n",
        "model.add(Dense(units=1,activation='linear'))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8a0wr94aTyjg"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNZPb5lKioX0",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "- Compile the model\n",
        "- Use \"sgd\" optimizer\n",
        "- for calculating loss, use mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEQUP3VaiuT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd') #optimizer is the hyper parameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbBpnOtfT0wd"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9o45OHdjDhA",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- epochs: 50\n",
        "- batch size: 128\n",
        "- specify validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y6tA30XjOH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bd3160c-91ec-4918-c9f3-40488831907a"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.3, verbose=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 230109 samples, validate on 98619 samples\n",
            "Epoch 1/50\n",
            "230109/230109 [==============================] - 4s 18us/sample - loss: 2170.9574 - val_loss: 1667.3144\n",
            "Epoch 2/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 2801.3435 - val_loss: 4230.1639\n",
            "Epoch 3/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.5704 - val_loss: 4230.9372\n",
            "Epoch 4/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.4752 - val_loss: 4232.8618\n",
            "Epoch 5/50\n",
            "230109/230109 [==============================] - 3s 15us/sample - loss: 4314.2848 - val_loss: 4230.2242\n",
            "Epoch 6/50\n",
            "230109/230109 [==============================] - 4s 17us/sample - loss: 4314.1330 - val_loss: 4230.7592\n",
            "Epoch 7/50\n",
            "230109/230109 [==============================] - 4s 17us/sample - loss: 4314.1353 - val_loss: 4230.5237\n",
            "Epoch 8/50\n",
            "230109/230109 [==============================] - 4s 17us/sample - loss: 4314.2385 - val_loss: 4230.1794\n",
            "Epoch 9/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4313.9934 - val_loss: 4230.8469\n",
            "Epoch 10/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.4516 - val_loss: 4230.9810\n",
            "Epoch 11/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2087 - val_loss: 4230.1698\n",
            "Epoch 12/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.6425 - val_loss: 4230.5515\n",
            "Epoch 13/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.2532 - val_loss: 4231.7358\n",
            "Epoch 14/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.4802 - val_loss: 4230.7217\n",
            "Epoch 15/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.6000 - val_loss: 4231.4205\n",
            "Epoch 16/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.1129 - val_loss: 4236.9837\n",
            "Epoch 17/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.0017 - val_loss: 4230.3432\n",
            "Epoch 18/50\n",
            "230109/230109 [==============================] - 3s 15us/sample - loss: 4314.2262 - val_loss: 4230.1819\n",
            "Epoch 19/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2639 - val_loss: 4230.5549\n",
            "Epoch 20/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.5331 - val_loss: 4230.9208\n",
            "Epoch 21/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.3017 - val_loss: 4232.2654\n",
            "Epoch 22/50\n",
            "230109/230109 [==============================] - 3s 15us/sample - loss: 4314.3130 - val_loss: 4232.5001\n",
            "Epoch 23/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.3026 - val_loss: 4233.9601\n",
            "Epoch 24/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.0360 - val_loss: 4233.5725\n",
            "Epoch 25/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.5965 - val_loss: 4236.0203\n",
            "Epoch 26/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2229 - val_loss: 4230.1774\n",
            "Epoch 27/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.4978 - val_loss: 4232.3072\n",
            "Epoch 28/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.1760 - val_loss: 4230.1973\n",
            "Epoch 29/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.1775 - val_loss: 4230.2197\n",
            "Epoch 30/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.4259 - val_loss: 4230.2223\n",
            "Epoch 31/50\n",
            "230109/230109 [==============================] - 4s 17us/sample - loss: 4314.1642 - val_loss: 4230.1912\n",
            "Epoch 32/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.3570 - val_loss: 4230.8608\n",
            "Epoch 33/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2122 - val_loss: 4237.1465\n",
            "Epoch 34/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.4861 - val_loss: 4231.7649\n",
            "Epoch 35/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.4019 - val_loss: 4230.2663\n",
            "Epoch 36/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.2604 - val_loss: 4230.2686\n",
            "Epoch 37/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.3763 - val_loss: 4231.6920\n",
            "Epoch 38/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2910 - val_loss: 4230.1639\n",
            "Epoch 39/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.5289 - val_loss: 4234.3695\n",
            "Epoch 40/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.3444 - val_loss: 4231.3284\n",
            "Epoch 41/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.6144 - val_loss: 4234.7579\n",
            "Epoch 42/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2972 - val_loss: 4230.1944\n",
            "Epoch 43/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.5351 - val_loss: 4231.9034\n",
            "Epoch 44/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.3940 - val_loss: 4231.5220\n",
            "Epoch 45/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.4932 - val_loss: 4230.1639\n",
            "Epoch 46/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.2779 - val_loss: 4230.3475\n",
            "Epoch 47/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.4473 - val_loss: 4233.5022\n",
            "Epoch 48/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.1888 - val_loss: 4230.2309\n",
            "Epoch 49/50\n",
            "230109/230109 [==============================] - 4s 15us/sample - loss: 4314.3865 - val_loss: 4230.6778\n",
            "Epoch 50/50\n",
            "230109/230109 [==============================] - 4s 16us/sample - loss: 4314.1788 - val_loss: 4237.4483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW4SEP8kT2ls"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJDoix_7JU61",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "- Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdH8pYBIjHGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss= model.evaluate(X_test, y_test, verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUpDD74Xjh01",
        "colab_type": "text"
      },
      "source": [
        "### Manual predictions\n",
        "- Test the predictions on manual inputs\n",
        "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler\n",
        "- Example of manual input: [123.430000,\t122.30999, 116.250000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvuH-c31lLiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "y_pred=np.round(model.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSiMhJPpk3GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test=[123.430000, 122.30999, 116.250000]\n",
        "ntest=np.array(new_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV2YlRfPWfi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp=scaler.transform(ntest.reshape(1,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Zt3bcSWoiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9eabf4d6-7eca-46ae-b38d-fb5facd7bf26"
      },
      "source": [
        "pred=model.predict(inp)\n",
        "pred"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[60.910503]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va6RbDTTWvLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}